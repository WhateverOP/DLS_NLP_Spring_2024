{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1q77WixYXvCFQtvRD-RbCQe7zC06hn7d7","timestamp":1708365361858},{"file_id":"12BxEICwjMhOcIQID1zn06K6kFG92GZcf","timestamp":1708035269638},{"file_id":"1pYR9hzeFxq1T5kZThLvgA7bkmcNQtbrq","timestamp":1707661673565}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"999c7ae90ae34a4ab451a57a544403cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e6a18404dfc44f989dabc09c4b7aeaa","IPY_MODEL_b7cb884ee8f94b29b990bdc8908c0830","IPY_MODEL_abc8fa2646f4460595d2ff3ba516188a"],"layout":"IPY_MODEL_c433ea217a614365899f60a6b00e5cc9"}},"1e6a18404dfc44f989dabc09c4b7aeaa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4d3af00e0434c2a8f70209a7a3c05fd","placeholder":"​","style":"IPY_MODEL_76e7027d8b244bca8b62f59f22d33d7c","value":"Map: 100%"}},"b7cb884ee8f94b29b990bdc8908c0830":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5be38397f0d246d2a46a7a3197e74e9c","max":4745,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb8d17f13944467ea8c9dd041de192bf","value":4745}},"abc8fa2646f4460595d2ff3ba516188a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84be5b7938b84eba89e54ed0534fa043","placeholder":"​","style":"IPY_MODEL_68a05e2ae89f4c8390bc52984c377143","value":" 4745/4745 [00:07&lt;00:00, 880.12 examples/s]"}},"c433ea217a614365899f60a6b00e5cc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4d3af00e0434c2a8f70209a7a3c05fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76e7027d8b244bca8b62f59f22d33d7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5be38397f0d246d2a46a7a3197e74e9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb8d17f13944467ea8c9dd041de192bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84be5b7938b84eba89e54ed0534fa043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68a05e2ae89f4c8390bc52984c377143":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cac6fdf1f22445fbd2f85bd03caea8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1947ed632e9e413b9898e9952700013c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61a8f816e2764dbd95281a5b945425e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcd7a7654bb146c88730271722b28f24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8025b49cca445c5b04e8a58b0425028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcc29f74349140f5b55d6c93d2550f13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"940e20c13e2e43f6822ebe93c4c626d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61a8f816e2764dbd95281a5b945425e4","placeholder":"​","style":"IPY_MODEL_fcd7a7654bb146c88730271722b28f24","value":"Map: 100%"}},"9f822aa6357244119254426dc35a39bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cac6fdf1f22445fbd2f85bd03caea8d","max":528,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1947ed632e9e413b9898e9952700013c","value":528}},"44694226bf1e476ea792c69977e9aff8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8025b49cca445c5b04e8a58b0425028","placeholder":"​","style":"IPY_MODEL_dcc29f74349140f5b55d6c93d2550f13","value":" 528/528 [00:00&lt;00:00, 741.94 examples/s]"}},"133fa13dde324c5b88d5674d0537c8ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b136097fd43d4142947fff0cc7038c83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_940e20c13e2e43f6822ebe93c4c626d9","IPY_MODEL_9f822aa6357244119254426dc35a39bd","IPY_MODEL_44694226bf1e476ea792c69977e9aff8"],"layout":"IPY_MODEL_133fa13dde324c5b88d5674d0537c8ec"}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\" width=\"400\"></p>\n","\n","# Глубокое обучение. Часть 2\n","# Домашнее задание по теме \"Механизм внимания\""],"metadata":{"id":"Ji8KtYOVGs8_"}},{"cell_type":"markdown","source":["Это домашнее задание проходит в формате peer-review. Это означает, что его будут проверять ваши однокурсники. Поэтому пишите разборчивый код, добавляйте комментарии и пишите выводы после проделанной работы.\n","\n","В этом задании вы будете решать задачу классификации математических задач по темам (многоклассовая классификация) с помощью Transformer.\n","\n","В качестве датасета возьмем датасет математических задач по разным темам. Нам необходим следующий файл:\n","\n","[Файл с классами](https://docs.google.com/spreadsheets/d/1IMRxByfg7gjoZ5i7rxvuNDvSrbdOJOc-/edit?usp=drive_link&ouid=104379615679964018037&rtpof=true&sd=true)"],"metadata":{"id":"UAr-M8_1GJ6W"}},{"cell_type":"markdown","source":["**Hint:** не перезаписывайте модели, которые вы получите на каждом из этапов этого дз. Они ещё понадобятся."],"metadata":{"id":"1fybMcmV0YRA"}},{"cell_type":"code","source":["! pip install -U accelerate\n","! pip install -U transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-eABCzgLdFu","executionInfo":{"status":"ok","timestamp":1713124612240,"user_tz":-180,"elapsed":26024,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"328cf8e8-48f0-43ca-ea26-52b831631ed1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.39.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}]},{"cell_type":"code","source":["from google.colab import output\n","output.enable_custom_widget_manager()\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path_to_data = '/content/drive/MyDrive/Deep_Learning_MIPT_2/hw_transformers/data_problems.xlsx'\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from tqdm.auto import tqdm\n","from nltk.tokenize import word_tokenize\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","import nltk\n","from nltk.corpus import stopwords\n","\n","from collections import Counter\n","from typing import List\n","import string\n","\n","import random\n","\n","from transformers import DistilBertModel\n","from transformers import DistilBertTokenizer\n","\n","import seaborn as sns\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","from transformers import AutoTokenizer, AutoModel\n","\n","!pip install datasets -q\n","import datasets\n","from datasets import load_metric\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import torchsummary\n","\n","sns.set(palette='summer')\n","sns.set(style=\"whitegrid\", font_scale=1.)\n","RUSSIAN_STOP_WORDS = set(stopwords.words('russian'))\n","\n","!pip install evaluate -q\n","\n","import transformers\n","import evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCyPz9Uo8YXi","executionInfo":{"status":"ok","timestamp":1713124678403,"user_tz":-180,"elapsed":26042,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"6daab6bd-ebe6-48fc-9fb3-153f8a122681"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cuda\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["init_df = pd.read_excel(path_to_data)\n","\n","print(f'init_df.shape = {init_df.shape}')\n","print(f'init_df.keys() = {init_df.keys()}')\n","\n","df = init_df.drop(columns=['Unnamed: 0'])\n","\n","df = df.rename(columns={'Задача': 'text', 'Тема': 'label'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XH3EntW8aZw","executionInfo":{"status":"ok","timestamp":1713124706370,"user_tz":-180,"elapsed":1867,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"e16162f9-637d-4bcf-e9e8-6d9a244f442a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["init_df.shape = (5273, 3)\n","init_df.keys() = Index(['Unnamed: 0', 'Задача', 'Тема'], dtype='object')\n"]}]},{"cell_type":"code","source":["labels_vocab = list(set(df['label']))\n","label2ind = {char: i for i, char in enumerate(labels_vocab)}\n","ind2label = {i: char for char, i in label2ind.items()}"],"metadata":{"id":"_EJh4JOc8acE","executionInfo":{"status":"ok","timestamp":1713124706371,"user_tz":-180,"elapsed":21,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df.groupby('label').count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"GYHjczl18aeo","executionInfo":{"status":"ok","timestamp":1713124706372,"user_tz":-180,"elapsed":21,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"4fc40ab8-e246-446a-ac19-4f882c1e5dc1"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               text\n","label              \n","Геометрия       371\n","Графы           384\n","Дирихле         441\n","Инвариант       235\n","Комбинаторика  1020\n","Многочлен       426\n","Теория чисел   2396"],"text/html":["\n","  <div id=\"df-d45b1815-c1c8-42b0-8cce-fed350f29ab0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Геометрия</th>\n","      <td>371</td>\n","    </tr>\n","    <tr>\n","      <th>Графы</th>\n","      <td>384</td>\n","    </tr>\n","    <tr>\n","      <th>Дирихле</th>\n","      <td>441</td>\n","    </tr>\n","    <tr>\n","      <th>Инвариант</th>\n","      <td>235</td>\n","    </tr>\n","    <tr>\n","      <th>Комбинаторика</th>\n","      <td>1020</td>\n","    </tr>\n","    <tr>\n","      <th>Многочлен</th>\n","      <td>426</td>\n","    </tr>\n","    <tr>\n","      <th>Теория чисел</th>\n","      <td>2396</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d45b1815-c1c8-42b0-8cce-fed350f29ab0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d45b1815-c1c8-42b0-8cce-fed350f29ab0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d45b1815-c1c8-42b0-8cce-fed350f29ab0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-85af6177-f1f7-45e4-8214-6211b3ddf041\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85af6177-f1f7-45e4-8214-6211b3ddf041')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-85af6177-f1f7-45e4-8214-6211b3ddf041 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\\u0413\\u0435\\u043e\\u043c\\u0435\\u0442\\u0440\\u0438\\u044f\",\n          \"\\u0413\\u0440\\u0430\\u0444\\u044b\",\n          \"\\u041c\\u043d\\u043e\\u0433\\u043e\\u0447\\u043b\\u0435\\u043d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 766,\n        \"min\": 235,\n        \"max\": 2396,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          371,\n          384,\n          426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df_shuffled = shuffle(df)\n","ds = datasets.Dataset.from_pandas(df_shuffled)"],"metadata":{"id":"cNV9-bSh9Lfg","executionInfo":{"status":"ok","timestamp":1713124706372,"user_tz":-180,"elapsed":18,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(df_shuffled.iloc[0])\n","print(ds[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qNsf28n9Lha","executionInfo":{"status":"ok","timestamp":1713124706372,"user_tz":-180,"elapsed":17,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"26ab77ed-6e59-4a6d-97eb-1a2f0e093195"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["text     Найдите число нулей, на которое оканчивается ч...\n","label                                         Теория чисел\n","Name: 4072, dtype: object\n","{'text': 'Найдите число нулей, на которое оканчивается число \\xa011100 – 1. ', 'label': 'Теория чисел', '__index_level_0__': 4072}\n"]}]},{"cell_type":"code","source":["ds_splitted = ds.remove_columns(\"__index_level_0__\").train_test_split(test_size=0.1)"],"metadata":{"id":"Z4qbKn7Z80HT","executionInfo":{"status":"ok","timestamp":1713125201416,"user_tz":-180,"elapsed":482,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def preprocess_text(text):\n","    processed_text = text.lower().translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n","    processed_text_no_sw = ' '.join([word for word in processed_text.split(' ') if word not in RUSSIAN_STOP_WORDS and word != ''])\n","    return processed_text_no_sw"],"metadata":{"id":"ebr6xLR585Wy","executionInfo":{"status":"ok","timestamp":1713125204750,"user_tz":-180,"elapsed":412,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["rubert_tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n","rubert_tiny_backbone = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\", output_attentions=True)"],"metadata":{"id":"ayKSFHQH80J9","executionInfo":{"status":"ok","timestamp":1713125205396,"user_tz":-180,"elapsed":285,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iwPLd8sORJjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ds_splitted['train']['text'][0])\n","preprocessed_text = preprocess_text(ds_splitted['train']['text'][0])\n","print(preprocessed_text)\n","tokenized_preprocessed_text = rubert_tokenizer.encode_plus(preprocessed_text, max_length=max_len, add_special_tokens=True,\n","                                                           padding='max_length', truncation=True, return_tensors='pt')\n","print(tokenized_preprocessed_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_AN8jbWRJmL","executionInfo":{"status":"ok","timestamp":1713126445644,"user_tz":-180,"elapsed":15,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"6af9604d-fb21-4987-e251-e25d19029789"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["В треугольнике ABC  AB = BC,  ∠B = 20°.  Точка M на основании AC такова, что  AM : MC = 1 : 2,  точка H – проекция C на BM. Найдите угол AHB.\n","треугольнике abc  ab bc   ∠b 20°   точка m основании ac такова  am mc 1 2   точка h – проекция c bm найдите угол ahb\n","{'input_ids': tensor([[    2,   330,  3091, 14381, 12789, 16284,  1420,   750,  1420,    69,\n","           750,     1,   619,  1831, 10667,    80, 20106,  2714,  9533,  1091,\n","           782,    80,   750,    21,    22, 10667,    75,     1,  2225,  3807,\n","          2356,    70,    69,   572,  3854, 26718,   626,   331, 24505, 20938,\n","           831,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]])}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SPG8l8IhRJ_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s9W1u7XuRjyg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len = 128\n","\n","def preprocess_function_rubert(examples):\n","    preprocessed_text = preprocess_text(examples[\"text\"])\n","    model_inputs = rubert_tokenizer.encode_plus(preprocessed_text, max_length=max_len, add_special_tokens=True,\n","                                         padding='max_length', truncation=True, return_tensors='pt')\n","    labels = label2ind[examples[\"label\"]]\n","    model_inputs[\"labels\"] = labels\n","\n","    return model_inputs"],"metadata":{"id":"PWCPNjnC80MK","executionInfo":{"status":"ok","timestamp":1713126467832,"user_tz":-180,"elapsed":4,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["tokenized_ds_splitted = ds_splitted.map(preprocess_function_rubert)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["999c7ae90ae34a4ab451a57a544403cd","1e6a18404dfc44f989dabc09c4b7aeaa","b7cb884ee8f94b29b990bdc8908c0830","abc8fa2646f4460595d2ff3ba516188a","c433ea217a614365899f60a6b00e5cc9","d4d3af00e0434c2a8f70209a7a3c05fd","76e7027d8b244bca8b62f59f22d33d7c","5be38397f0d246d2a46a7a3197e74e9c","fb8d17f13944467ea8c9dd041de192bf","84be5b7938b84eba89e54ed0534fa043","68a05e2ae89f4c8390bc52984c377143","0cac6fdf1f22445fbd2f85bd03caea8d","1947ed632e9e413b9898e9952700013c","61a8f816e2764dbd95281a5b945425e4","fcd7a7654bb146c88730271722b28f24","a8025b49cca445c5b04e8a58b0425028","dcc29f74349140f5b55d6c93d2550f13","940e20c13e2e43f6822ebe93c4c626d9","9f822aa6357244119254426dc35a39bd","44694226bf1e476ea792c69977e9aff8","133fa13dde324c5b88d5674d0537c8ec","b136097fd43d4142947fff0cc7038c83"]},"id":"M2GDIYE9-M7L","executionInfo":{"status":"ok","timestamp":1713126477782,"user_tz":-180,"elapsed":7307,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"2e3da2e7-981d-4493-8993-764b0a58a0b2"},"execution_count":84,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4745 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"999c7ae90ae34a4ab451a57a544403cd"}},"metadata":{"application/vnd.jupyter.widget-view+json":{"colab":{"custom_widget_manager":{"url":"https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"}}}}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/528 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b136097fd43d4142947fff0cc7038c83"}},"metadata":{"application/vnd.jupyter.widget-view+json":{"colab":{"custom_widget_manager":{"url":"https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"}}}}}]},{"cell_type":"code","source":["# tokenized_ds_splitted  = tokenized_ds_splitted.remove_columns([\"text\", \"label\"])\n","# tokenized_ds_splitted  = tokenized_ds_splitted.remove_columns([\"attention_mask\"])"],"metadata":{"id":"H5Qej3NcOpGm","executionInfo":{"status":"ok","timestamp":1713126477782,"user_tz":-180,"elapsed":16,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["tokenized_ds_splitted"],"metadata":{"id":"cCnSDRqU_jKe","executionInfo":{"status":"ok","timestamp":1713126477783,"user_tz":-180,"elapsed":14,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"54b116b4-39ba-4b18-ca30-f8fe369435fd","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 4745\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","        num_rows: 528\n","    })\n","})"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":[],"metadata":{"id":"ymN-r299_XHN","executionInfo":{"status":"ok","timestamp":1713126477785,"user_tz":-180,"elapsed":12,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["len(tokenized_ds_splitted['train']['input_ids'][0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmuKby8UPjyO","executionInfo":{"status":"ok","timestamp":1713126478250,"user_tz":-180,"elapsed":474,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"2e2141db-119c-479e-98fc-3733c75481e7"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["len(tokenized_ds_splitted['train']['text'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szjHUBgUQGMt","executionInfo":{"status":"ok","timestamp":1713126478250,"user_tz":-180,"elapsed":9,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"1951d87e-d17e-44ea-ecc5-29357157a374"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["141"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["len(tokenized_ds_splitted['train']['token_type_ids'][0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajrkCSmnQ3nq","executionInfo":{"status":"ok","timestamp":1713126478637,"user_tz":-180,"elapsed":392,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"323a0bd9-ad30-4404-ced5-ab343584d5ff"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":[],"metadata":{"id":"XgsMwtVvQ3p-","executionInfo":{"status":"ok","timestamp":1713126478637,"user_tz":-180,"elapsed":9,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N9WCt4hmQ3r9","executionInfo":{"status":"ok","timestamp":1713126478638,"user_tz":-180,"elapsed":9,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FJSMgk39Pj0e","executionInfo":{"status":"ok","timestamp":1713126478638,"user_tz":-180,"elapsed":8,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":["### Задание 1 (2 балла)\n","\n","Напишите кастомный класс для модели трансформера для задачи классификации, использующей в качествке backbone какую-то из моделей huggingface.\n","\n","Т.е. конструктор класса должен принимать на вход название модели и подгружать её из huggingface, а затем использовать в качестве backbone (достаточно возможности использовать в качестве backbone те модели, которые упомянуты в последующих пунктах)"],"metadata":{"id":"t395freCxpOE"}},{"cell_type":"code","source":["### This is just an interface example. You may change it if you want.\n","\n","class TransformerClassificationModel(nn.Module):\n","    def __init__(self, num_classes, backbone):\n","        super(TransformerClassificationModel, self).__init__()\n","        self.backbone = backbone\n","        self.drop = nn.Dropout(p=0.2)\n","        self.fc = nn.Linear(self.backbone.config.hidden_size, num_classes)\n","        self.loss_fn = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self, inputs, attention_mask, labels):\n","        outputs = self.backbone(input_ids=inputs, attention_mask=attention_mask)\n","        pooled_output = outputs[0][:, 0, :]\n","        logits = self.fc(pooled_output)\n","        attention_weights = outputs[-1][-1]\n","        if labels is not None:\n","            loss = self.loss_fn(logits, labels)\n","        outputs = transformers.modeling_outputs\n","        return logits, attention_weights\n","\n","    def freeze_backbone(self):\n","        for param in self.backbone.parameters():\n","            param.requires_grad = False\n","\n","    def unfreeze_backbone(self):\n","        for param in self.backbone.parameters():\n","            param.requires_grad = True"],"metadata":{"id":"eX4VGWquyiMx","executionInfo":{"status":"ok","timestamp":1713126479259,"user_tz":-180,"elapsed":6,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":["### Задание 2 (1 балл)\n","\n","Напишите функцию заморозки backbone у модели (если необходимо, возвращайте из функции модель)"],"metadata":{"id":"Vd3kxX6hy0d4"}},{"cell_type":"code","source":["# def freeze_backbone_function(model: TransformerClassificationModel):\n","#     pass"],"metadata":{"id":"U8IuDosbzKe8","executionInfo":{"status":"ok","timestamp":1713126479845,"user_tz":-180,"elapsed":3,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":["### Задание 3 (2 балла)\n","\n","Напишите функцию, которая будет использована для тренировки (дообучения) трансформера (TransformerClassificationModel). Функция должна поддерживать обучение с замороженным и размороженным backbone."],"metadata":{"id":"kybkw6MSzd-K"}},{"cell_type":"code","source":["# import copy\n","\n","# def train_transformer(transformer_model, freeze_backbone=True)\n","#     model = copy.copy(transformer_model)\n","#     ### YOUR CODE IS HERE\n","\n","#     return finetuned_model"],"metadata":{"id":"EDhrD0BHzxi4","executionInfo":{"status":"ok","timestamp":1713126480115,"user_tz":-180,"elapsed":2,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QOyt2ilfGZzy","executionInfo":{"status":"ok","timestamp":1713126480491,"user_tz":-180,"elapsed":3,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":["### Задание 4 (1 балл)\n","\n","Проверьте вашу функцию из предыдущего пункта, дообучив двумя способами\n","*cointegrated/rubert-tiny2* из huggingface."],"metadata":{"id":"eUqhI4mV_RTI"}},{"cell_type":"code","source":["model_rubert_tiny = TransformerClassificationModel(len(label2ind), rubert_tiny_backbone).to(device)"],"metadata":{"id":"nuxOCBQHAKZC","executionInfo":{"status":"ok","timestamp":1713126485826,"user_tz":-180,"elapsed":4,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["data_collator_rubert_tiny = transformers.DataCollatorForTokenClassification(tokenizer=rubert_tokenizer)"],"metadata":{"id":"mQo3gWLbGn-G","executionInfo":{"status":"ok","timestamp":1713126485827,"user_tz":-180,"elapsed":3,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["training_args_rubert_tiny = transformers.TrainingArguments(\n","        output_dir=\"/content/drive/MyDrive/Deep_Learning_MIPT_2/hw_transformers/rubert_tiny\",\n","        evaluation_strategy=\"epoch\",\n","        learning_rate=2e-5,\n","        per_device_train_batch_size=4,\n","        per_device_eval_batch_size=4,\n","        weight_decay=0.01,\n","        save_total_limit=3,\n","        num_train_epochs=2,\n","    )"],"metadata":{"id":"-FGhY4yXGoAc","executionInfo":{"status":"ok","timestamp":1713126488280,"user_tz":-180,"elapsed":374,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["trainer_rubert_tiny = transformers.Trainer(\n","    model=model_rubert_tiny,\n","    args=training_args_rubert_tiny,\n","    train_dataset=tokenized_ds_splitted[\"train\"],\n","    eval_dataset=tokenized_ds_splitted[\"test\"],\n","    tokenizer=rubert_tokenizer,\n","    data_collator=data_collator_rubert_tiny,\n",")"],"metadata":{"id":"Oytg9uKEJU43","executionInfo":{"status":"ok","timestamp":1713126489712,"user_tz":-180,"elapsed":2,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["trainer_rubert_tiny.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"NfGolRc_MReD","executionInfo":{"status":"error","timestamp":1713126493860,"user_tz":-180,"elapsed":1374,"user":{"displayName":"Pavel Oskin","userId":"12795831590389692658"}},"outputId":"d1b59ebc-7daa-4a96-e9c1-ac62b6a0eb6d"},"execution_count":97,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['attention_mask']","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-97-02104bda9aaa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer_rubert_tiny\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1781\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_call\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mno_labels_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         batch = pad_without_fast_tokenizer_warning(\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mno_labels_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpad_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Restore the state of the warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3286\u001b[0m         \u001b[0;31m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3288\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3289\u001b[0m                 \u001b[0;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m                 \u001b[0;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['attention_mask']"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AHeWDEzuMRga"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Задание 5 (1 балл)\n","\n","Обучите *tbs17/MathBert* (с замороженным backbone и без заморозки), проанализируйте результаты. Сравните скоры с первым заданием. Получилось лучше или нет? Почему?"],"metadata":{"id":"zRi7tkoOAjon"}},{"cell_type":"code","source":["### YOUR CODE IS HERE (probably, similar on the previous step)"],"metadata":{"id":"XKtd3YgNA14E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Задание 6 (1 балл)\n","\n","Напишите функцию для отрисовки карт внимания первого слоя для моделей из задания"],"metadata":{"id":"EuU6Di26017B"}},{"cell_type":"code","source":["def draw_first_layer_attention_maps(attention_head_ids: List, text: str, model: TransformerClassificationModel):\n","    pass"],"metadata":{"id":"guzGxfcV1Cba"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Задание 7 (1 балл)\n","\n","Проведите инференс для всех моделей **ДО ДООБУЧЕНИЯ** на 2-3 текстах из датасета. Посмотрите на головы Attention первого слоя в каждой модели на выбранных текстах (отрисуйте их отдельно).\n","\n","Попробуйте их проинтерпретировать. Какие связи улавливают карты внимания? (если в модели много голов Attention, то проинтерпретируйте наиболее интересные)"],"metadata":{"id":"Iu0adKw4BLtF"}},{"cell_type":"code","source":["### YOUR CODE IS HERE"],"metadata":{"id":"U2gEF3vkB6eR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Задание 8 (1 балл)\n","\n","Сделайте то же самое для дообученных моделей. Изменились ли карты внимания и связи, которые они улавливают? Почему?"],"metadata":{"id":"pBNVrOpCCLqk"}},{"cell_type":"code","source":["### YOUR CODE IS HERE"],"metadata":{"id":"F5229WBICWEr"},"execution_count":null,"outputs":[]}]}