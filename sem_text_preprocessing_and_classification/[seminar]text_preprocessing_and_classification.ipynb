{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PcL7r1hqySq"
   },
   "source": [
    "# Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-sGLT0vp4jt"
   },
   "source": [
    "## Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn8EWAjnr18g"
   },
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btBdBLxbgrNV",
    "outputId": "a7fe3f5c-0700-424e-e917-819007411386"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/opv002/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq-QOD9NlO_Q",
    "outputId": "e254cf47-27ef-46b7-c503-2bc58d835f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    }
   ],
   "source": [
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "tokens = word_tokenize(data.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFDKUzkS6Mci",
    "outputId": "0bbbcfce-22d9-4ea0-8912-877a3ec02baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I was going home when she rung.', 'It was a surprise.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(\"I was going home when she rung. It was a surprise.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQoG7qznyuf5"
   },
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/natasha/natasha-logos/master/natasha.svg\">](https://github.com/natasha/natasha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPeApu2mwYxY"
   },
   "source": [
    "[Razdel](https://natasha.github.io/razdel/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TwJj5Z2fvbeN"
   },
   "outputs": [],
   "source": [
    "# !pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy58Xd_vve-z",
    "outputId": "b5a29b12-0873-4d64-c116-db9da2a2e4f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 13, 'Кружка-термос'),\n",
       " Substring(14, 16, 'на'),\n",
       " Substring(17, 20, '0.5'),\n",
       " Substring(20, 21, 'л'),\n",
       " Substring(22, 23, '('),\n",
       " Substring(23, 28, '50/64'),\n",
       " Substring(29, 32, 'см³'),\n",
       " Substring(32, 33, ','),\n",
       " Substring(34, 37, '516'),\n",
       " Substring(37, 38, ';'),\n",
       " Substring(38, 41, '...'),\n",
       " Substring(41, 42, ')')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize, sentenize\n",
    "text = 'Кружка-термос на 0.5л (50/64 см³, 516;...)'\n",
    "list(tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrmhCpNdQo6r"
   },
   "source": [
    "#### Регулярные выражения\n",
    "\n",
    "Исчерпывающий пост https://habr.com/ru/post/349860/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IccRpcG06Mfd",
    "outputId": "1560c7ef-9dde-45e8-fb5b-0998190cf8ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['super', 'c', 'a', 'a', 'c', 'a', 'c']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall('[abc]|up|super', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Je8YPHLZPJW7",
    "outputId": "e731e421-3a25-4039-a40f-18d281952745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['49', '43', '23', '12']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\d{1,2}', 'These are some numbers: 49 and 432312')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fzde8MX1PJXA",
    "outputId": "5d638269-ee23-42df-8ed7-50dd63349c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How to split text'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[,\\.?!]','','How, to? split. text!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyswV9nuPJXF",
    "outputId": "d4d23159-3e92-4e1d-f7d1-be6ea5dee092"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'can', 'play', 'football']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^A-z]',' ','I 123 can 45 play 67 football').split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz0wIRkRswOQ"
   },
   "source": [
    "### Удаление неинформативных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trdPOBM2jEMf"
   },
   "source": [
    "#### N-граммы\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--466CQV1q--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/78nf1vryed8h1tz05fim.gif\" height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYEBfCxLic3R",
    "outputId": "1e6f9ac7-a21f-427a-a421-6d936f2f6b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all',), ('work',), ('and',), ('no',), ('play',)]\n",
      "[('all', 'work'), ('work', 'and'), ('and', 'no'), ('no', 'play'), ('play', 'makes')]\n"
     ]
    }
   ],
   "source": [
    "unigram = list(nltk.ngrams(tokens, 1))\n",
    "bigram = list(nltk.ngrams(tokens, 2))\n",
    "print(unigram[:5])\n",
    "print(bigram[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AFeZqejmWwN",
    "outputId": "8f9fff61-090e-4e05-adc3-f9052610d5bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Популярные униграммы:  [(('all',), 2), (('work',), 2), (('and',), 2), (('no',), 2), (('play',), 2)]\n",
      "Популярные биграммы:  [(('all', 'work'), 2), (('work', 'and'), 2), (('and', 'no'), 2), (('no', 'play'), 2), (('play', 'makes'), 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "print('Популярные униграммы: ', FreqDist(unigram).most_common(5))\n",
    "print('Популярные биграммы: ', FreqDist(bigram).most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W3jJ56hnBFu"
   },
   "source": [
    "#### Стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIBwQ3nBnEfV",
    "outputId": "5f6c8413-a652-4ea6-9b6d-450e099075cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/opv002/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1nk-TqEslRl",
    "outputId": "e56801a2-c8bf-479a-f1e8-ed312cdb3a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yourselves', 'between', 'them', 'd', 'am', \"weren't\", 'yours', 'his', 'about', 'him', 'll', 'ma', \"isn't\", 'theirs', 'some', 'y', 'as', \"didn't\", 'for', \"you've\", 'your', 're', 'when', 'at', 'they', 'very', 'out', 'own', 'nor', 'are', 've', 'had', 'only', 'was', 'such', 'through', 'off', 'during', 'each', 'doing', 'same', 'than', 'weren', 'herself', 'just', \"wasn't\", 'into', 'did', 'himself', 'you', 'be', \"haven't\", 'hasn', 'does', 'any', 'couldn', 'shouldn', 'and', 'because', 'of', 'a', 'do', 'ain', 'the', 'further', 'me', \"should've\", 'here', \"mightn't\", 'isn', 'so', \"needn't\", 'ourselves', 'yourself', \"you'd\", 'why', 'wouldn', 'myself', 'other', 'o', \"you're\", 'before', 'is', \"wouldn't\", 'up', 'aren', \"shouldn't\", 'most', 'its', 'if', 'didn', 'there', \"shan't\", 'having', 'been', 's', 'don', 't', \"it's\", 'that', 'in', 'all', \"couldn't\", 'few', 'm', 'wasn', 'with', 'until', 'it', \"she's\", 'but', \"that'll\", \"you'll\", \"mustn't\", 'hers', 'themselves', 'will', 'what', 'to', 'needn', 'or', 'were', 'i', 'over', 'shan', \"won't\", 'while', 'an', 'down', 'this', 'which', 'we', 'won', 'against', 'from', 'who', 'those', 'on', 'haven', 'their', 'mightn', 'no', 'whom', 'mustn', 'hadn', 'can', 'itself', 'once', \"hadn't\", 'ours', 'then', 'doesn', \"doesn't\", 'under', 'again', 'she', 'how', 'now', 'our', 'my', 'where', \"don't\", 'not', 'has', 'after', 'more', \"aren't\", 'being', 'these', 'both', 'too', 'should', 'her', 'above', 'he', 'below', 'by', \"hasn't\", 'have'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFkfJm9ktAVa",
    "outputId": "11e85df4-d2e6-4f9f-ff23-f6cc50fee22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'play', 'makes', 'jack', 'dull', 'boy', ',', 'work', 'play']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in tokens if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5QoqlHiS83f",
    "outputId": "628de9cf-0e10-48ee-e743-448512a7cd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh-MYv6e-skM"
   },
   "source": [
    "#### Стемминг vs Лемматизация\n",
    "* ‘Caring’ -> Лемматизация -> ‘Care’\n",
    "* ‘Caring’ -> Стемминг -> ‘Car’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAUKc1oTiQjf"
   },
   "source": [
    "### Стемминг\n",
    "* процесс нахождения основы слова для заданного исходного слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iRVu-TrON4sq"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "words = [\"game\", \"gaming\", \"gamed\", \"games\", \"compacted\"]\n",
    "words_ru = ['корова', 'мальчики', 'мужчины', 'столом', 'убежала']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9HTGfsBN9eX",
    "outputId": "e4392b8d-20cb-4a60-9a09-1326d2fdf3f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['game', 'game', 'game', 'game', 'compact']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "list(map(ps.stem, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5qZkB-oODkW",
    "outputId": "b2094c0b-6f4f-431b-801e-107fac105e9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['коров', 'мальчик', 'мужчин', 'стол', 'убежа']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = SnowballStemmer(language='russian')\n",
    "list(map(ss.stem, words_ru))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbTXbi9FJXr1"
   },
   "source": [
    "### Лематизация\n",
    "* процесс приведения словоформы к лемме — её нормальной (словарной) форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QF4nnEz00thb"
   },
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "\n",
    "raw_ru = \"\"\"Не существует научных доказательств в пользу эффективности НЛП, оно\n",
    "признано псевдонаукой. Систематические обзоры указывают, что НЛП основано на\n",
    "устаревших представлениях об устройстве мозга, несовместимо с современной\n",
    "неврологией и содержит ряд фактических ошибок.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mljfOAC4n21I",
    "outputId": "5bf02a63-b1cd-4923-cef6-610c496bad73"
   },
   "outputs": [],
   "source": [
    "# !pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Zez7jnXl5uJ",
    "outputId": "51782962-44ee-431d-c025-5a70226bf9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "не существовать научный доказательство в польза эффективность нлп, оно\n",
      "признать псевдонаукой. систематический обзор указывают, что нлп основать на\n",
      "устаревший представление о устройство мозга, несовместимый с современной\n",
      "неврология и содержать ряд фактический ошибок.\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "pymorphy_results = list(map(lambda x: morph.parse(x), raw_ru.split(' ')))\n",
    "print(' '.join([res[0].normal_form for res in pymorphy_results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7MDqIvWib4O",
    "outputId": "93dee74a-4769-4473-a6bb-e3e0b71bad2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DENNIS : listen , strange woman lie in pond distribute sword \n",
      " be no basis for a system of government .   Supreme executive power derive from \n",
      " a mandate from the masse , not from some farcical aquatic ceremony .\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load('en')\n",
    "spacy_results = nlp(raw)\n",
    "print(' '.join([token.lemma_ for token in spacy_results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVC5gjCRk5bD"
   },
   "source": [
    "[Сравнение PyMorphy2 и PyMystem3](https://habr.com/ru/post/503420/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yim_NVYA6MeS"
   },
   "source": [
    "### Part-of-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2t_MamYKqbSk",
    "outputId": "17c3a9fc-4fc2-4d0f-9353-a76e653cf6f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', OpencorporaTag('PRCL')),\n",
       " ('существовать', OpencorporaTag('VERB,impf,intr sing,3per,pres,indc')),\n",
       " ('научный', OpencorporaTag('ADJF,Qual plur,gent')),\n",
       " ('доказательство', OpencorporaTag('NOUN,inan,neut plur,gent')),\n",
       " ('в', OpencorporaTag('PREP')),\n",
       " ('польза', OpencorporaTag('NOUN,inan,femn sing,accs')),\n",
       " ('эффективность', OpencorporaTag('NOUN,inan,femn sing,gent')),\n",
       " ('нлп,', OpencorporaTag('UNKN')),\n",
       " ('оно\\nпризнать', OpencorporaTag('PRTS,perf,past,pssv neut,sing'))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "[(res[0].normal_form, res[0].tag) for res in pymorphy_results[:9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Doa85yw6JWea",
    "outputId": "794ec981-0378-4020-e316-f1e2045d8949"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DENNIS', 'PROPN'),\n",
       " (':', 'PUNCT'),\n",
       " ('listen', 'VERB'),\n",
       " (',', 'PUNCT'),\n",
       " ('strange', 'ADJ'),\n",
       " ('woman', 'NOUN'),\n",
       " ('lie', 'VERB')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "[(token.lemma_, token.pos_) for token in spacy_results[:7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall tensorflow_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVGJLVjLtFDp",
    "outputId": "c01be447-80df-4477-c875-28889e7b7e36"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall rnnmorph -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rnnmorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ms2yeEFqrtZ",
    "outputId": "dd9131e0-82bd-46a7-e54e-1bed989ff9fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 20:18:36.113028: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-25 20:18:36.113117: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-25 20:18:36.185385: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-25 20:18:36.339661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-25 20:18:38.082079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrnnmorph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RNNMorphPredictor\n\u001b[1;32m      3\u001b[0m predictor \u001b[38;5;241m=\u001b[39m RNNMorphPredictor(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mru\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m rnnmorph_result \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_ru\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m [(token\u001b[38;5;241m.\u001b[39mnormal_form, token\u001b[38;5;241m.\u001b[39mpos, token\u001b[38;5;241m.\u001b[39mtag) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m rnnmorph_result[:\u001b[38;5;241m7\u001b[39m]]\n",
      "File \u001b[0;32m~/miniconda3/envs/test_env/lib/python3.10/site-packages/rnnmorph/predictor.py:91\u001b[0m, in \u001b[0;36mRNNMorphPredictor.predict\u001b[0;34m(self, words, include_all_forms)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, words: List[\u001b[38;5;28mstr\u001b[39m], include_all_forms: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[WordFormOut]:\n\u001b[0;32m---> 91\u001b[0m     words_probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_config\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_sentence_forms(words, words_probabilities, include_all_forms)\n",
      "File \u001b[0;32m~/miniconda3/envs/test_env/lib/python3.10/site-packages/rnnmorph/model.py:379\u001b[0m, in \u001b[0;36mLSTMMorphoAnalysis.predict_probabilities\u001b[0;34m(self, sentences, batch_size, build_config)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m sentences]\n\u001b[1;32m    377\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentences)\n\u001b[0;32m--> 379\u001b[0m words \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_samples, max_sentence_len), dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m    380\u001b[0m grammemes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_samples, max_sentence_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrammeme_vectorizer_input\u001b[38;5;241m.\u001b[39mgrammemes_count()),\n\u001b[1;32m    381\u001b[0m                      dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    382\u001b[0m chars \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_samples, max_sentence_len, build_config\u001b[38;5;241m.\u001b[39mchar_max_word_length), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n",
      "File \u001b[0;32m~/miniconda3/envs/test_env/lib/python3.10/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "predictor = RNNMorphPredictor(language=\"ru\")\n",
    "rnnmorph_result = predictor.predict(raw_ru.split(' '))\n",
    "[(token.normal_form, token.pos, token.tag) for token in rnnmorph_result[:7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_Slt2R76Mgk"
   },
   "source": [
    "### Named entities recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvB43ZHT6MhR",
    "outputId": "3d490cfc-0b7f-4cb1-f655-7e9ca16f6a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0-_oFwwqAwN"
   },
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIwDfmrYOMfi"
   },
   "source": [
    "### Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6DaLniC6MhY"
   },
   "source": [
    "#### 20 newsgroups\n",
    "Датасет с 18000 новостей, сгруппированных по 20 темам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uS7IJNW6Mhb",
    "outputId": "ebc2f876-92c7-4032-a422-d51b2e3c2c4a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMbagpJE6Mhh",
    "outputId": "152aa470-abef-47d0-deb1-2bcef6280e07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QReW1K46Mhn",
    "outputId": "d243da37-1e2a-4a19-e22b-960f369915c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZtRIQmNQ4H0"
   },
   "source": [
    "#### Рассмотрим подвыборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OhwuCp5B6Mhz",
    "outputId": "53f9bb20-9762-49b3-f2f2-0327bde7d576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOREsv336MiA",
    "outputId": "f91d5c50-4e47-4ba9-cbbe-37acf3df847a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: rych@festival.ed.ac.uk (R Hawkes)\n",
      "Subject: 3DS: Where did all the texture rules go?\n",
      "Lines: 21\n",
      "\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "======================================================================\n",
      "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
      "Virtual Environment Laboratory\n",
      "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
      "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBnDG-TN6MiF",
    "outputId": "33bc189f-0161-4287-bf48-e78fcdadd683"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XlZYpodRYDI"
   },
   "source": [
    "#### TF-IDF(напоминание)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohUk2n3jRbNp"
   },
   "source": [
    "$n_{\\mathbb{d}\\mathbb{w}}$ - число вхождений слова $\\mathbb{w}$ в документ $\\mathbb{d}$;<br>\n",
    "$N_{\\mathbb{w}}$ - число документов, содержащих $\\mathbb{w}$;<br>\n",
    "$N$ - число документов; <br><br>\n",
    "\n",
    "$p(\\mathbb{w}, \\mathbb{d}) = N_{\\mathbb{w}} / N$ - вероятность наличия слова $\\mathbb{w}$ в любом документе $\\mathbb{d}$\n",
    "<br>\n",
    "$P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}}) = (N_{\\mathbb{w}} / N)^{n_{\\mathbb{d}\\mathbb{w}}}$ - вероятность встретить $n_{\\mathbb{d}\\mathbb{w}}$ раз слово $\\mathbb{w}$ в документе $\\mathbb{d}$<br><br>\n",
    "\n",
    "$-\\log{P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}})} = n_{\\mathbb{d}\\mathbb{w}} \\cdot \\log{(N / N_{\\mathbb{w}})} = TF(\\mathbb{w}, \\mathbb{d}) \\cdot IDF(\\mathbb{w})$<br><br>\n",
    "\n",
    "$TF(\\mathbb{w}, \\mathbb{d}) = n_{\\mathbb{d}\\mathbb{w}}$ - term frequency;<br>\n",
    "$IDF(\\mathbb{w}) = \\log{(N /N_{\\mathbb{w}})}$ - inverted document frequency;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQvcMiFH6MiM"
   },
   "source": [
    "#### Давайте векторизуем эти тексты с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "98LLAoZO6MiU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baXLU0lj6MiY"
   },
   "source": [
    "#### Некоторые параметры:\n",
    "* input : string {‘filename’, ‘file’, ‘content’}\n",
    "*  lowercase : boolean, default True\n",
    "*  preprocessor : callable or None (default)\n",
    "*  tokenizer : callable or None (default)\n",
    "*  stop_words : string {‘english’}, list, or None (default)\n",
    "*  ngram_range : tuple (min_n, max_n)\n",
    "*  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
    "*  min_df : float in range [0.0, 1.0] or int, default=1\n",
    "*  max_features : int or None, default=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-m81BJxZFwJ"
   },
   "source": [
    "#### Перебор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f7padHL6MiZ",
    "outputId": "a60445fa-ad78-4efb-ad13-51a8a59f5650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 34118)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nf2s4HCY6Mie",
    "outputId": "159178a7-2cb6-438f-93fd-2532ec410368"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 42307)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', '00000', '000000', '000005102000', '000021',\n",
       "       '000062David42', '0000VEC', '0001'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hwlTWapZR8M",
    "outputId": "e2ced468-e4d8-497c-8f27-4262fba6eea1"
   },
   "outputs": [],
   "source": [
    "# vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYfpk0ds6Mij",
    "outputId": "a605ac46-771c-44cd-c5c9-0774625740d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df, max_df\n",
    "vectorizer = TfidfVectorizer(min_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ookt99atZ8sS",
    "outputId": "48acde37-ce1c-46e4-e131-bf3d99a36d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'from', 'in', 'lines', 'of', 'organization', 'subject',\n",
       "       'the', 'to'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1 = 0.0004916420845624386\n",
      "idf_1 = 2034.0\n",
      "log_idf_1 = 7.617759576608505\n"
     ]
    }
   ],
   "source": [
    "df_1 = 1/len(newsgroups_train.data)\n",
    "print(f'df_1 = {df_1}')\n",
    "idf_1 = len(newsgroups_train.data)/1\n",
    "print(f'idf_1 = {idf_1}')\n",
    "log_idf_1 = np.log(len(newsgroups_train.data)/1)\n",
    "print(f'log_idf_1 = {log_idf_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_200 = 0.09832841691248771\n",
      "idf_200 = 10.17\n",
      "log_idf_200 = 2.3194422100604686\n"
     ]
    }
   ],
   "source": [
    "df_200 = 200/len(newsgroups_train.data)\n",
    "print(f'df_200 = {df_200}')\n",
    "idf_200 = len(newsgroups_train.data)/200\n",
    "print(f'idf_200 = {idf_200}')\n",
    "log_idf_200 = np.log(len(newsgroups_train.data)/200)\n",
    "print(f'log_idf_200 = {log_idf_200}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 16552)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.0005)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['compel', 'compeling', 'compendium', 'competence', 'competetive',\n",
       "       'competetors', 'competion', 'competitions', 'competitiveness',\n",
       "       'competitor'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[5000:5010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e_h6c0X6Mim",
    "outputId": "1164d096-e211-478d-cb27-cc782b71690e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min documents with this word = 20.34\n",
      "max documents with this word = 1627.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2034, 2391)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'min documents with this word = {0.01*len(newsgroups_train.data)}')\n",
    "print(f'max documents with this word = {0.8*len(newsgroups_train.data)}')\n",
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUhOyx4NihL0",
    "outputId": "c5bdb88a-8a3b-4654-b0b4-9a8a5c79e132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1236)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram_range\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=0.03, max_df=0.9)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "7074cdSF6MjC",
    "outputId": "378752c9-3ae1-436f-d3c5-568363006d90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/opv002/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'oh , think landed miracle work , thirst hunger come conference bird'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# стоп-слова, preproc\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def preproc_nltk(text):\n",
    "    #text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
    "    return ' '.join([wnl.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stopWords])\n",
    "\n",
    "st = \"Oh, I think I ve landed Where there are miracles at work,  For the thirst and for the hunger Come the conference of birds\"\n",
    "preproc_nltk(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LIW3hCSy6MjX",
    "outputId": "338c71af-0740-4c8f-c058-684dd087ad97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 31689)\n",
      "CPU times: user 9.58 s, sys: 0 ns, total: 9.58 s\n",
      "Wall time: 9.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(preprocessor=preproc_nltk)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lUmyAzJEB1SU",
    "outputId": "f7b9009d-14f0-4436-e2e5-b7082f7aa6b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh , I think I land miracle work ,   thirst hunger come conference bird'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preproc_spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "texts = newsgroups_train.data.copy()\n",
    "\n",
    "def preproc_spacy(text):\n",
    "    spacy_results = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in spacy_results if token.lemma_ not in stopWords])\n",
    "preproc_spacy(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0C5Ent0nG5zj",
    "outputId": "1af1abe9-bc09-480f-ced0-5caf77a7e0d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 29646)\n",
      "CPU times: user 17.3 s, sys: 187 ms, total: 17.5 s\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_texts = []\n",
    "for doc in nlp.pipe(texts, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n",
    "    new_texts.append(' '.join([tok.lemma_ for tok in doc if tok.lemma not in stopWords]))\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(new_texts)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df, max_df\n",
    "vectorizer = TfidfVectorizer(min_df=0.8)\n",
    "vectors = vectorizer.fit_transform(new_texts)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for word in vectorizer.get_feature_names_out():\n",
    "    print(word in stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 14725)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df, max_df\n",
    "vectorizer = TfidfVectorizer(max_df=0.0005)\n",
    "vectors = vectorizer.fit_transform(new_texts)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1351)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram_range\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=0.03, max_df=0.9)\n",
    "vectors = vectorizer.fit_transform(new_texts)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lXAPHZA6Mj0"
   },
   "source": [
    "#### Итоговая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZYcRkQ86Mj1",
    "outputId": "72392257-a3e9-405a-9238-169e7c0d115c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', 'attempt', 'choose', 'engineering', 'human', 'look',\n",
       "       'of this', 'report', 'technology', 'understand'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, max_features=1000) # выберет 1000 с максимальным tf-idf\n",
    "vectors = vectorizer.fit_transform(new_texts)\n",
    "vectorizer.get_feature_names_out()[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQHTlj3q6Mj6"
   },
   "source": [
    "#### Можем посмотреть на косинусную меру между векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = vectors.todense()[0]\n",
    "(vector != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jo4fKtAXqCl-",
    "outputId": "81b8f469-e889-4c92-942e-63f0a526311d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kweWqI8ztDwC",
    "outputId": "b729a5b3-fd07-4bc5-99fe-75909a02cd8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.8023598820059"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(map(lambda x: (x != 0).sum(), vectors.todense())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsVQhR9y6Mj8",
    "outputId": "378d430b-f6d2-4f76-e2d9-bda51d8479de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "type(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tS2G0ZZC6MkN",
    "outputId": "7dc5ec75-cf8e-4c15-a759-631dc63c6c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vectors = vectors.todense()\n",
    "dense_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "LGgb5aP76MkU"
   },
   "outputs": [],
   "source": [
    "def cosine_sim(v1, v2):\n",
    "    # v1, v2 (1 x dim)\n",
    "    return np.array(v1 @ v2.T / norm(v1) / norm(v2))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_FrKM6k6MkY",
    "outputId": "462e7b13-1aa4-4506-e605-49feaf5ab150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(dense_vectors[0], dense_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "L1XF-isH6Mkh"
   },
   "outputs": [],
   "source": [
    "cosines = []\n",
    "for i in range(10):\n",
    "    cosines.append(cosine_sim(dense_vectors[0], dense_vectors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODwgYEbe6Mkl",
    "outputId": "b6959653-9dea-438a-9590-9c2afedceab4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0000000000000002,\n",
       " 0.04191279776414236,\n",
       " 0.00586838361101993,\n",
       " 0.09771238093526102,\n",
       " 0.0706091645327028,\n",
       " 0.06745764842966309,\n",
       " 0.026714182362747592,\n",
       " 0.22853760897260955,\n",
       " 0.03163642012466396,\n",
       " 0.06928662593161493]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1, 3, 2, 0, 2, 0, 2, 1, 2, 1]\n",
    "cosines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRZyJP3c6Mkq"
   },
   "source": [
    "#### Обучим любую известную модель на полученных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RDfl72A6Mks",
    "outputId": "881d3b15-aa8b-479b-ce66-a06e91e47824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627,), (407,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(dense_vectors, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjfwduNp6Mlo",
    "outputId": "8d86a9ea-2a38-487a-8147-1b2d6f5c7ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.34 s, sys: 0 ns, total: 2.34 s\n",
      "Wall time: 2.35 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6Evwipx6Mlv",
    "outputId": "943c6663-6329-4ad4-d040-1f54b4ea80f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9262899262899262"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EBZRbXT6Mly",
    "outputId": "1b992f83-1c25-4e3d-f536-b284d660e1e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9213759213759214"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "accuracy_score(y_test, sgd.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5OAwBJ0LuPb"
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "SKLGAYPvPJcJ"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "embeddings_pretrained = api.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "fmH3vc7FSCuP"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "proc_words = [preproc_nltk(text).split() for text in newsgroups_train.data]\n",
    "embeddings_trained = Word2Vec(proc_words, # data for model to train on\n",
    "                 vector_size=100,                 # embedding vector size\n",
    "                 min_count=3,             # consider words that occured at least 5 times\n",
    "                 window=3).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':', 'acooper', '@', 'mac.cc.macalstr.edu', 'subject', ':', ':', 'thought', 'christian', 'organization', ':', 'macalester', 'college', 'line', ':', '94', 'article', '<', '1993apr15.050750.3893', '@', 'nuscc.nus.sg', '>', ',', 'cmtan', '@', 'iss.nus.sg', '(', 'tan', 'chade', 'meng', '-', 'dan', ')', 'writes', ':', '>', 'sandvik', '@', 'newton.apple.com', '(', 'kent', 'sandvik', ')', 'writes', ':', '>', ':', 'article', '<', '1q338l', '$', 'cva', '@', 'uxa.ecn.bgu.edu', '>', ',', 'gsu0033', '@', 'uxa.ecn.bgu.edu', '(', 'eric', '>', ':', 'mola', ')', 'wrote', ':', '>', ':', '>', 'christianity', 'infectious', 'cult', '.', 'reason', 'flourish', '>', ':', '>', '1', ')', 'give', 'people', 'without', 'hope', 'driven', 'purpose', 'life', '>', ':', '>', 'safety', 'blanked', 'hide', 'behind', '.', '``', 'oh', 'wow', '..', '>', ':', '>', 'follow', 'christian', 'moral', 'standard', 'get', 'eternal', 'happiness', '.', \"''\", '>', ':', '>', ':', 'agree', 'many', 'case', 'primitive', 'emotional', 'feeling', 'based', '>', ':', \"'haha\", ',', 'wo', \"n't\", 'laugh', 'hell', \"'\", 'mentality', 'make', 'certain', 'religion', '>', ':', 'attractive', 'certain', 'personality', '.', '>', '>', 'agree', 'u', ',', 'would', 'like', 'make', 'small', 'point', '.', 'xtianity', ',', '&', '>', 'dogmatic', 'religion', ',', 'attract', 'people', 'without', 'hope', 'etc', '>', 'also', 'attract', '``', 'average', \"''\", 'people', 'well', '.', 'believe', 'xtainity', ',', 'thru', '>', 'escapist', 'doctrine', '&', 'absolutist', 'attitude', ',', 'provides', 'great', 'psychological', '>', 'shelter', 'day-to-day', 'frustration', ',', 'unhappiness', '&', 'fear', 'uncertainty', '>', '&', 'unknown', 'etc', '.', '>', 'good', 'point', ',', 'think', '``', 'average', \"''\", 'people', 'take', 'christianity', 'much', 'fear', 'escapism', ',', ',', 'quite', 'simply', ',', 'way', 'improve', 'social', 'life', ',', 'get', 'involved', 'american', 'culture', ',', 'kid', 'immigrant', 'example', '.', 'since', 'overwhelming', 'major', 'religion', 'western', 'world', '(', 'form', ')', ',', 'simply', 'choice', 'people', 'take', 'bored', 'want', 'something', 'new', 'life', ',', 'somethong', 'new', ',', 'ordinary', '.', 'seems', 'little', 'weak', ',', 'long', \"n't\", 'hurt', 'anybody', '...', '>', 'buddha', 'something', 'say', 'attractiveness', 'religion', ':', '>', '>', '``', 'driven', 'fear', ',', 'man', 'worship', 'sacred', 'mountain', ',', 'sacred', 'stone', ',', '>', 'sacred', 'tree', '.', \"''\", '>', '>', 'however', ',', 'buddha', 'also', 'said', ',', '>', '>', \"''\", 'somebody', 'find', 'peace', 'religion', ',', 'let', \"''\", '.', '>', '>', 'good', 'quote', ',', 'agree', ',', 'let', \"'s\", 'make', 'sure', 'alter', 'scond', 'one', 'includes', 'something', 'like', '``', '...', 'let', ',', 'long', 'preventing', 'others', 'finding', 'peace', '.', \"''\", 'something', 'like', '.', '(', 'course', ',', 'suppose', ',', 'someone', 'really', '``', 'peace', \"''\", ',', 'would', 'need', 'inflicting', 'evangelism', ')', '>', 'personally', ',', 'feel', 'since', 'religion', 'poweful', '>', 'psychological', 'effect', ',', 'let', 'theist', '.', 'problem', '>', 'religion', 'cause', 'enormous', 'harm', 'non-believers', 'humanity', 'whole', '>', '(', 'holy', 'war', ',', 'inquisition', ',', 'inter-religious', 'hatred', ',', 'impedence', 'science', '>', '&', 'intellectual', 'progress', ',', 'us-', '&', '-them', 'attitude', 'etc', 'etc', '.', 'need', 'say', '?', ')', '.', '>', 'really', \"n't\", 'know', '.', 'comment', '?', '>', 'well', ',', 'sure', 'thing', 'live', 'life', '.', 'popularity', 'seems', 'come', 'go', '.', 'remember', 'first', 'entered', 'high', 'school', ',', 'atheist', '(', 'always', ')', '7', 'friend', '.', 'time', ',', '5', '7', 'converted', ',', 'always', 'christianity', '(', 'also', 'immigrant', 'taiwan', ',', 'son', 'immigrant', ',', 'hence', 'earlier', 'gross', 'generalization', ')', '.', 'christianity', 'seems', 'lot', 'popular', 'people', 'ever', '(', 'since', \"'ve\", 'noticing', ')', '.', 'maybe', 'perception', 'chagning', '.', 'know', '?', 'one', 'perfectly', 'willing', 'live', 'let', 'live', ',', 'long', 'set', 'abstract', 'rights/agreements', 'treat', ':', 'desire', 'hurt', 'notion', '.', 'well-put', 'argument', 'usenet', ',', 'never', 'good', '.', 'argumentation', 'really', 'seem', 'apply', 'christian', '(', 'even', 'atheist', ')', '-', 'must', 'simply', 'step', 'person', 'take', 'naturally', ',', 'almost', ',', '``', 'instinctively', \"''\", '...', 'best', 'regard', ',', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'adam', 'john', 'cooper', \"''\", 'verily', ',', 'often', 'laughed', 'weakling', '*', '*', 'thought', 'good', 'simply', '*', '*', 'acooper', '@', 'macalstr.edu', 'claw', '.', \"''\", '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '>', '--', '>', '>', 'unenlightened', 'one', '>', '--', '--', '--', '--', '--', '--', '--', '--', '--', '+', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '>', '|', '``', 'buddhism', 'characteristic', 'would', '>', 'tan', 'chade', 'meng', '|', 'expected', 'cosmic', 'religion', 'future', ':', '>', 'singapore', '|', 'transcends', 'personal', 'god', ',', 'avoids', 'dogma', 'theology', ';', '>', 'cmtan', '@', 'iss.nus.sg', '|', 'cover', 'natural', '&', 'spiritual', ',', '>', '|', 'based', 'religious', 'sense', 'aspiring', 'experience', '>', '|', 'thing', ',', 'natural', 'spiritual', ',', 'meaningful', '>', '|', 'unity', \"''\", '--', 'einstein', '>', '--', '--', '--', '--', '--', '--', '--', '--', '--', '+', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '>', '>', '>']\n"
     ]
    }
   ],
   "source": [
    "print(proc_words[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_pretrained.vectors.shape[1])\n",
    "print(embeddings_trained.vectors.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "0Lq20widPJcO"
   },
   "outputs": [],
   "source": [
    "def vectorize_sum(comment, embeddings):\n",
    "    \"\"\"\n",
    "    implement a function that converts preprocessed comment to a sum of token vectors\n",
    "    \"\"\"\n",
    "    embedding_dim = embeddings.vectors.shape[1]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "\n",
    "    for word in preproc_nltk(comment).split():\n",
    "        if word in embeddings:\n",
    "            features += embeddings[f'{word}']\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1KaMKBHsSHd",
    "outputId": "65336ef9-6d63-4c40-881d-d22ca4b8b2c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13566"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_trained.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krjpVRsLPJcf",
    "outputId": "0f24b897-f3c5-4ee7-84fe-1ca5a2abeafe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627, 25), (407, 25))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_pretrained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWhQ007PPJcn",
    "outputId": "ba51dbd6-e7ef-4ed5-eac0-948d32f76a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051597051597052"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oT_Rr4nOUUu8",
    "outputId": "08a28d12-283e-4eab-d80c-6208cc6ceadd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627, 100), (407, 100))"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_trained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVMeZBLbVMjO",
    "outputId": "653442de-cfa8-4170-bfa6-1f87e00a6e29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opv002/miniconda3/envs/test_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8452088452088452"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_K8NLmDVds1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "11.8333px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.717px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
