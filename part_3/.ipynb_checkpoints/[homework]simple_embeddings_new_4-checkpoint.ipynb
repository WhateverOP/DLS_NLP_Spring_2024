{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot3c4fjZwC4T"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2JdzEXmwRU5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fc8iHXIVwDwj"
   },
   "source": [
    "***Some parts of the notebook are almost the copy of [ mmta-team course](https://github.com/mmta-team/mmta_fall_2020). Special thanks to mmta-team for making them publicly available. [Original notebook](https://github.com/mmta-team/mmta_fall_2020/blob/master/tasks/01_word_embeddings/task_word_embeddings.ipynb).***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D0wm5jt6j0U"
   },
   "source": [
    "<b> Прочитайте семинар, пожалуйста, для успешного выполнения домашнего задания. В конце ноутка напишите свой вывод. Работа без вывода оценивается ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIWqBuEa6j0b"
   },
   "source": [
    "## Задача поиска схожих по смыслу предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUkwMPLA6j0g"
   },
   "source": [
    "Мы будем ранжировать вопросы [StackOverflow](https://stackoverflow.com) на основе семантического векторного представления "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNRXIEfu5a3Q"
   },
   "source": [
    "До этого в курсе не было речи про задачу ранжировния, поэтому введем математическую формулировку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS9FwWNd5a3S"
   },
   "source": [
    "## Задача ранжирования(Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdwY9-f75a3T"
   },
   "source": [
    "* $X$ - множество объектов\n",
    "* $X^l = \\{x_1, x_2, ..., x_l\\}$ - обучающая выборка\n",
    "<br>На обучающей выборке задан порядок между некоторыми элементами, то есть нам известно, что некий объект выборки более релевантный для нас, чем другой:\n",
    "* $i \\prec j$ - порядок пары индексов объектов на выборке $X^l$ c индексами $i$ и $j$\n",
    "### Задача:\n",
    "построить ранжирующую функцию $a$ : $X \\rightarrow R$ такую, что\n",
    "$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG2IGBsh5a3U"
   },
   "source": [
    "<img src=\"https://d25skit2l41vkl.cloudfront.net/wp-content/uploads/2016/12/Featured-Image.jpg\" width=500, height=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQk_rolFwT_h"
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUe1PGXn6j0l"
   },
   "source": [
    "Будем использовать предобученные векторные представления слов на постах Stack Overflow.<br>\n",
    "[A word2vec model trained on Stack Overflow posts](https://github.com/vefstathiou/SO_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mYkI54Y-rk7a"
   },
   "outputs": [],
   "source": [
    "# !wget https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O8YJTOYv6j0s"
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin?download=1\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIcT_g-C6j1E"
   },
   "source": [
    "#### Как пользоваться этими векторами?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWO5SPDY6j1G"
   },
   "source": [
    "Посмотрим на примере одного слова, что из себя представляет embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KeSBlQfk6j1J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (200,)\n"
     ]
    }
   ],
   "source": [
    "word = 'dog'\n",
    "if word in wv_embeddings:\n",
    "    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T4Eq-D1qxpMJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of words: 1787145\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of words: {len(wv_embeddings.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT6NTCys6j1Q"
   },
   "source": [
    "Найдем наиболее близкие слова к слову `dog`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n08z2PjMwC5o"
   },
   "source": [
    "#### Вопрос 1:\n",
    "* Входит ли слов `cat` топ-5 близких слов к слову `dog`? Какое место? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nYwVz0xG6j1U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('animal', 0.8564180135726929),\n",
       " ('dogs', 0.7880866527557373),\n",
       " ('mammal', 0.7623804211616516),\n",
       " ('cats', 0.7621253728866577),\n",
       " ('animals', 0.760793924331665)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method most_simmilar\n",
    "'''your code'''\n",
    "wv_embeddings.most_similar('dog')[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответ: да, входит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai48-5vv6j1d"
   },
   "source": [
    "### Векторные представления текста\n",
    "\n",
    "Перейдем от векторных представлений отдельных слов к векторным представлениям вопросов, как к **среднему** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектора, то его нужно пропустить. Если вопрос не содержит ни одного известного слова, то нужно вернуть нулевой вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EhNuxBJd6j1f"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "# you can use your tokenizer\n",
    "# for example, from nltk.tokenize import WordPunctTokenizer\n",
    "class MyTokenizer:\n",
    "    def __init__(self, ext_tokenizer, ext_stopwords, ext_punctuation):\n",
    "        self.tokenizer = ext_tokenizer\n",
    "        self.stopwords = ext_stopwords\n",
    "        self.punctuation = ext_punctuation\n",
    "    def tokenize(self, text):\n",
    "        tokens = self.tokenizer.tokenize(text.lower())\n",
    "        tokens_no_sw_punct = [token for token in tokens if token not in self.stopwords and token not in self.punctuation]\n",
    "        return tokens_no_sw_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = WordPunctTokenizer()\n",
    "sw = set(stopwords.words('english'))\n",
    "punct = string.punctuation\n",
    "MyTokenizer_obj = MyTokenizer(tk, sw, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YHcvu6186j1m"
   },
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, tokenizer, dim=200):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        embeddings: наше векторное представление\n",
    "        dim: размер любого вектора в нашем представлении\n",
    "        \n",
    "        return: векторное представление для вопроса\n",
    "    \"\"\"\n",
    "    \n",
    "    question_tokens = tokenizer.tokenize(question)\n",
    "    question_vector = []\n",
    "    for token in question_tokens:\n",
    "        if token in embeddings:\n",
    "            question_vector.append(embeddings[token])\n",
    "\n",
    "    if len(question_vector) > 0:\n",
    "        return np.mean(question_vector, axis=0)\n",
    "    return np.zeros(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5Q_4j7r6j1u"
   },
   "source": [
    "Теперь у нас есть метод для создания векторного представления любого предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsJSNkhm6j1y"
   },
   "source": [
    "#### Вопрос 2:\n",
    "* Какая третья(с индексом 2) компонента вектора предложения `I love neural networks` (округлите до 2 знаков после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a62r11cT6j10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.29\n"
     ]
    }
   ],
   "source": [
    "'''your code'''\n",
    "q_ex_mean_vec3 = question_to_vec('I love neural networks', wv_embeddings, MyTokenizer_obj)\n",
    "print(np.around(q_ex_mean_vec3[2],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответ: -1.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y60z4t6W6j16"
   },
   "source": [
    "### Оценка близости текстов\n",
    "\n",
    "Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями. \n",
    "\n",
    "Сгенерируем для каждого из $N$ вопросов $R$ случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели $R + 1$ примеров и смотреть на позицию дубликата. Мы хотим, чтобы дубликат был первым в ранжированном списке.\n",
    "\n",
    "#### Hits@K\n",
    "Первой простой метрикой будет количество корректных попаданий для какого-то $K$:\n",
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n",
    "* $\\begin{equation*}\n",
    "[x < 0 ] \\equiv \n",
    " \\begin{cases}\n",
    "   1, &x < 0\\\\\n",
    "   0, &x \\geq 0\n",
    " \\end{cases}\n",
    "\\end{equation*}$ - индикаторная функция\n",
    "* $q_i$ - $i$-ый вопрос\n",
    "* $q_i^{'}$ - его дубликат\n",
    "* $rank\\_q_i^{'}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$.\n",
    "\n",
    "#### DCG@K\n",
    "Второй метрикой будет упрощенная DCG метрика, учитывающая порядок элементов в списке путем домножения релевантности элемента на вес равный обратному логарифму номера позиции::\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n",
    "С такой метрикой модель штрафуется за большой ранк корректного ответа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHCnH-jw6j18"
   },
   "source": [
    "#### Вопрос 3:\n",
    "* Максимум `Hits@47 - DCG@1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответ: 1\n",
    "## Максимум Hits@47 = 1 (для ранков от 1 до 46 включительно)\n",
    "## Минимум DCG@1 = 0 (для ранков от 2 до бесконечности)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tFemBkP6j1-"
   },
   "source": [
    "<img src='https://hsto.org/files/1c5/edf/dee/1c5edfdeebce4b71a86bdf986d9f88f2.jpg' width=400, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sUSxk866j1_"
   },
   "source": [
    "#### Пример оценок\n",
    "\n",
    "Вычислим описанные выше метрики для игрушечного примера. \n",
    "Пусть\n",
    "* $N = 1$, $R = 3$\n",
    "* <font color='green'>\"Что такое python?\"</font> - вопрос $q_1$\n",
    "* <font color='red'>\"Что такое язык python?\"</font> - его дубликат $q_i^{'}$\n",
    "\n",
    "Пусть модель выдала следующий ранжированный список кандидатов:\n",
    "\n",
    "1. \"Как изучить с++?\"\n",
    "2. <font color='red'>\"Что такое язык python?\"</font>\n",
    "3. \"Хочу учить Java\"\n",
    "4. \"Не понимаю Tensorflow\"\n",
    "\n",
    "$\\Rightarrow rank\\_q_i^{'} = 2$\n",
    "\n",
    "Вычислим метрику *Hits@K* для *K = 1, 4*:\n",
    "\n",
    "- [K = 1] $\\text{Hits@1} =  [rank\\_q_i^{'} \\le 1)] = 0$\n",
    "- [K = 4] $\\text{Hits@4} =  [rank\\_q_i^{'} \\le 4] = 1$\n",
    "\n",
    "Вычислим метрику *DCG@K* для *K = 1, 4*:\n",
    "- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n",
    "- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Hits_K(rank, K):\n",
    "    return int(rank <= K)\n",
    "\n",
    "def calc_DCG_K(rank, K):\n",
    "    return int(rank <= K)/(np.log(1 + rank)/np.log(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4L6HJJC6j2B"
   },
   "source": [
    "#### Вопрос 4:\n",
    "* Вычислите `DCG@10`, если $rank\\_q_i^{'} = 9$(округлите до одного знака после запятой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(calc_DCG_K(9, 10),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответ: 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5xWOORI6j2F"
   },
   "source": [
    "### HITS\\_COUNT и DCG\\_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1q9WQOx6j2H"
   },
   "source": [
    "Каждая функция имеет два аргумента: $dup\\_ranks$ и $k$. $dup\\_ranks$ является списком, который содержит рейтинги дубликатов(их позиции в ранжированном списке). Например, $dup\\_ranks = [2]$ для примера, описанного выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F5VwySUB6j2J"
   },
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list индексов дубликатов\n",
    "        result: вернуть  Hits@k\n",
    "    \"\"\"\n",
    "    hits_value = []\n",
    "    for rank in dup_ranks:\n",
    "        hits_value.append(int(rank <= k))\n",
    "    return np.mean(hits_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "82hQaxCH6j2R"
   },
   "outputs": [],
   "source": [
    "def dcg_score(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list индексов дубликатов\n",
    "        result: вернуть DCG@k\n",
    "    \"\"\"\n",
    "    dcg_value = []\n",
    "    for rank in dup_ranks:\n",
    "        dcg_value.append(int(rank <= k)/(np.log(1 + rank)/np.log(2)))\n",
    "    return np.mean(dcg_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcwHeXN26j2Y"
   },
   "source": [
    "Протестируем функции. Пусть $N = 1$, то есть один эксперимент. Будем искать копию вопроса и оценивать метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fjISmOEW6j2h"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gLa_Wqfh6j2m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваш ответ HIT: [0.0, 1.0, 1.0, 1.0]\n",
      "Ваш ответ DCG: [0.0, 0.63093, 0.63093, 0.63093]\n"
     ]
    }
   ],
   "source": [
    "copy_answers = [\"How does the catch keyword determine the type of exception that was thrown\",]\n",
    "\n",
    "# наги кандидаты\n",
    "candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
    "                       \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                       \"NSLog array description not memory address\",\n",
    "                       \"PECL_HTTP not recognised php ubuntu\"],]\n",
    "# dup_ranks — позиции наших копий, так как эксперимент один, то этот массив длины 1\n",
    "dup_ranks = [2]\n",
    "\n",
    "# вычисляем метрику для разных k\n",
    "print('Ваш ответ HIT:', [hits_count(dup_ranks, k) for k in range(1, 5)])\n",
    "print('Ваш ответ DCG:', [round(dcg_score(dup_ranks, k), 5) for k in range(1, 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoHC3YoQ6j2t"
   },
   "source": [
    "У вас должно получиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "B0NFWq4f6j2u",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HITS</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCG</th>\n",
       "      <td>0</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1        2        3        4\n",
       "HITS  0  1.00000  1.00000  1.00000\n",
       "DCG   0  0.63093  0.63093  0.63093"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct_answers - метрика для разных k\n",
    "correct_answers = pd.DataFrame([[0, 1, 1, 1], [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]],\n",
    "                               index=['HITS', 'DCG'], columns=range(1,5))\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHZqgDTo6j0i"
   },
   "source": [
    "### Данные\n",
    "[arxiv link](https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit)\n",
    "\n",
    "`train.tsv` - выборка для обучения.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>**\n",
    "\n",
    "`validation.tsv` - тестовая выборка.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1628256058346,
     "user": {
      "displayName": "Deep Learning School",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhNf0RkP5WvkU5MixKfC1Sv3mb-9QWgAbC6VcfQvA=s64",
      "userId": "16549096980415837553"
     },
     "user_tz": -180
    },
    "id": "jKVK2lDGvrIe",
    "outputId": "51944c9b-d6e8-41af-bec4-bb35fba5d51b"
   },
   "outputs": [],
   "source": [
    "# !unzip stackoverflow_similar_questions.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hil2UsUG6j22"
   },
   "source": [
    "Считайте данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "B4EBho8s6j26"
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        '''your code'''\n",
    "        # data.extend(line.split('\\t'))\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkTxY3Mk9_nG"
   },
   "source": [
    "Нам понадобиться только файл validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "error",
     "timestamp": 1628256058355,
     "user": {
      "displayName": "Deep Learning School",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhNf0RkP5WvkU5MixKfC1Sv3mb-9QWgAbC6VcfQvA=s64",
      "userId": "16549096980415837553"
     },
     "user_tz": -180
    },
    "id": "PTVB9Tnp6j29",
    "outputId": "9c55c802-3d82-471d-eab2-195dabf5026c"
   },
   "outputs": [],
   "source": [
    "validation_data = read_corpus('./data/validation.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTHfL-9y6j3F"
   },
   "source": [
    "Кол-во строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "z6ubXhIe6j3H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3760"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaOQblBy6j3M"
   },
   "source": [
    "Размер нескольких первых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yRx6e-Pe6j3M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1001\n",
      "2 1001\n",
      "3 1001\n",
      "4 1001\n",
      "5 1001\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i + 1, len(validation_data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySQQp0oQt1Ep"
   },
   "source": [
    "### Ранжирование без обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iElEDhj-6j3R"
   },
   "source": [
    "Реализуйте функцию ранжирования кандидатов на основе косинусного расстояния. Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список **[(2, c), (0, a), (1, b)]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "K02JARKr6j3T"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, tokenizer, dim=200, test_out=False):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        candidates: массив строк(кандидатов) [a, b, c]\n",
    "        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n",
    "    \"\"\"\n",
    "    '''your code'''\n",
    "    question_tokens = tokenizer.tokenize(question)\n",
    "    question_vec = question_to_vec(question, embeddings, tokenizer)\n",
    "\n",
    "    init_pos_list = []\n",
    "    cand_list = []\n",
    "    cand_tokens_list = []\n",
    "    cos_sim_list = []\n",
    "    for i in range(0, len(candidates)):\n",
    "        init_pos_list.append(i)\n",
    "        cand_list.append(candidates[i])\n",
    "        cand_tokens = tokenizer.tokenize(candidates[i])\n",
    "        cand_tokens_list.append(cand_tokens)\n",
    "        cand_vec = question_to_vec(candidates[i], embeddings, tokenizer)\n",
    "        cos_sim = cosine_similarity(question_vec.reshape(1, -1), cand_vec.reshape(1, -1))[0][0]\n",
    "        cos_sim_list.append(cos_sim)\n",
    "\n",
    "    df = pd.DataFrame({'q':[question]*len(cand_list), 'q_tokens':[question_tokens]*len(cand_list),\n",
    "                       'init_pos':init_pos_list, 'cand':cand_list,\n",
    "                       'cand_tokens':cand_tokens_list, 'cos_sim':cos_sim_list,})\n",
    "    df = df.sort_values('cos_sim', ascending=False).reset_index(drop=True)\n",
    "    # return df\n",
    "\n",
    "    init_pos_cand = []\n",
    "    for i in range(0, len(df)):\n",
    "        init_pos_cand.append([df.iloc[i]['init_pos'], df.iloc[i]['cand']])\n",
    "\n",
    "    if test_out:\n",
    "        return init_pos_cand, df\n",
    "    else:\n",
    "        return init_pos_cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnBszTb76j3c"
   },
   "source": [
    "Протестируйте работу функции на примерах ниже. Пусть $N=2$, то есть два эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xvQgtP176j3h"
   },
   "outputs": [],
   "source": [
    "questions = ['converting string to list', 'Sending array via Ajax fails'] \n",
    "\n",
    "candidates = [['Convert Google results object (pure js) to Python object', # первый эксперимент\n",
    "               'C# create cookie from string and send it',\n",
    "               'How to use jQuery AJAX for an outside domain?'],\n",
    "              \n",
    "              ['Getting all list items of an unordered list in PHP',      # второй эксперимент\n",
    "               'WPF- How to update the changes in list item of a list',\n",
    "               'select2 not displaying search results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests_list = []\n",
    "# for question, q_candidates in zip(questions, candidates):\n",
    "#     tests = rank_candidates(question, q_candidates, wv_embeddings, MyTokenizer_obj, test_out=True)\n",
    "#     tests_list.append(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bPj1JGFi6j3m"
   },
   "outputs": [],
   "source": [
    "ranks_list = []\n",
    "for question, q_candidates in zip(questions, candidates):\n",
    "    ranks = rank_candidates(question, q_candidates, wv_embeddings, MyTokenizer_obj)\n",
    "    ranks_list.append(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 'C# create cookie from string and send it'],\n",
       "  [0, 'Convert Google results object (pure js) to Python object'],\n",
       "  [2, 'How to use jQuery AJAX for an outside domain?']],\n",
       " [[0, 'Getting all list items of an unordered list in PHP'],\n",
       "  [2, 'select2 not displaying search results'],\n",
       "  [1, 'WPF- How to update the changes in list item of a list']]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jm4cidj56j3q"
   },
   "source": [
    "Для первого экперимента вы можете полностью сравнить ваши ответы и правильные ответы. Но для второго эксперимента два ответа на кандидаты будут <b>скрыты</b>(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0LeKMIsn6j3s"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1724534416.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    [(*, 'Getting all list items of an unordered list in PHP'), #скрыт\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# должно вывести\n",
    "results = [[(1, 'C# create cookie from string and send it'),\n",
    "            (0, 'Convert Google results object (pure js) to Python object'),\n",
    "            (2, 'How to use jQuery AJAX for an outside domain?')],\n",
    "           [(*, 'Getting all list items of an unordered list in PHP'), #скрыт\n",
    "            (*, 'select2 not displaying search results'), #скрыт\n",
    "            (*, 'WPF- How to update the changes in list item of a list')]] #скрыт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1ttnIBe6j3x"
   },
   "source": [
    "Последовательность начальных индексов вы должны получить `для эксперимента 1`  1, 0, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WQgYDWd6j3y"
   },
   "source": [
    "#### Вопрос 5:\n",
    "* Какую последовательность начальных индексов вы получили `для эксперимента 2`(перечисление без запятой и пробелов, например, `102` для первого эксперимента?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответ: 021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPllOY-Y6j30"
   },
   "source": [
    "Теперь мы можем оценить качество нашего метода. Запустите следующие два блока кода для получения результата. Обратите внимание, что вычисление расстояния между векторами занимает некоторое время (примерно 10 минут). Можете взять для validation 1000 примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Z3q9sxddz-yU"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0a29a029e64eab91b638cd83d7fe42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking = []\n",
    "test_dfs = []\n",
    "max_validation_examples = 1000\n",
    "# max_validation_examples = 100\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks_tests = rank_candidates(q, ex, wv_embeddings, MyTokenizer_obj, test_out=True)\n",
    "    ranks = ranks_tests[0]\n",
    "    test_dfs.append(ranks_tests[1])\n",
    "    # ranks = rank_candidates(q, ex, wv_embeddings, MyTokenizer_obj)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDtS520v6j35"
   },
   "outputs": [],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "# for k in tqdm([1, 5, 10, 100]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: Multiline REGEX using VB Script\n",
      "most similar (was 1): Regex pattern not working in VB Script\n",
      "(['multiline', 'regex', 'using', 'vb', 'script'], ['regex', 'pattern', 'working', 'vb', 'script']) = 0.8309870362281799\n",
      "true similar (now 1): Regex pattern not working in VB Script\n",
      "(['multiline', 'regex', 'using', 'vb', 'script'], ['regex', 'pattern', 'working', 'vb', 'script']) = 0.8309870362281799\n"
     ]
    }
   ],
   "source": [
    "index = 22\n",
    "true_df = test_dfs[index][test_dfs[index]['init_pos'] == 0]\n",
    "print(f\"question: {test_dfs[index]['q'][0]}\")\n",
    "print(f\"most similar (was {test_dfs[index].iloc[0]['init_pos'] + 1}): {test_dfs[index].iloc[0]['cand']}\")\n",
    "print(f\"({test_dfs[index]['q_tokens'][0]}, {test_dfs[index].iloc[0]['cand_tokens']}) = {test_dfs[index].iloc[0]['cos_sim']}\")\n",
    "print(f\"true similar (now {true_df.index[0] + 1}): {true_df.iloc[0]['cand']}\")\n",
    "print(f\"({test_dfs[index]['q_tokens'][0]}, {true_df.iloc[0]['cand_tokens']}) = {true_df.iloc[0]['cos_sim']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q</th>\n",
       "      <th>q_tokens</th>\n",
       "      <th>init_pos</th>\n",
       "      <th>cand</th>\n",
       "      <th>cand_tokens</th>\n",
       "      <th>cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>0</td>\n",
       "      <td>Regex pattern not working in VB Script</td>\n",
       "      <td>[regex, pattern, working, vb, script]</td>\n",
       "      <td>0.830987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>369</td>\n",
       "      <td>Word counts in Python using regular expression</td>\n",
       "      <td>[word, counts, python, using, regular, express...</td>\n",
       "      <td>0.625896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>498</td>\n",
       "      <td>Convert Perl Regular Expression into Java Regu...</td>\n",
       "      <td>[convert, perl, regular, expression, java, reg...</td>\n",
       "      <td>0.623632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>778</td>\n",
       "      <td>How to replace curly quotation marks in a stri...</td>\n",
       "      <td>[replace, curly, quotation, marks, string, usi...</td>\n",
       "      <td>0.614143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>848</td>\n",
       "      <td>ELM/Haskell : use Regular expression(Regex) to...</td>\n",
       "      <td>[elm, haskell, use, regular, expression, regex...</td>\n",
       "      <td>0.598888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>609</td>\n",
       "      <td>Symfony: Logs are not shown in Toolbar</td>\n",
       "      <td>[symfony, logs, shown, toolbar]</td>\n",
       "      <td>-0.060448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>580</td>\n",
       "      <td>NoClassDefFoundError during Tomcat graceful sh...</td>\n",
       "      <td>[noclassdeffounderror, tomcat, graceful, shutd...</td>\n",
       "      <td>-0.070299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>918</td>\n",
       "      <td>VectorKit crash reports with MKMapSnapshotter ...</td>\n",
       "      <td>[vectorkit, crash, reports, mkmapsnapshotter, ...</td>\n",
       "      <td>-0.080530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>629</td>\n",
       "      <td>NSURLConnection crash on releasing NSMutableData</td>\n",
       "      <td>[nsurlconnection, crash, releasing, nsmutabled...</td>\n",
       "      <td>-0.113431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Multiline REGEX using VB Script</td>\n",
       "      <td>[multiline, regex, using, vb, script]</td>\n",
       "      <td>790</td>\n",
       "      <td>HTTPS exception in 3G with some Android devices</td>\n",
       "      <td>[https, exception, 3g, android, devices]</td>\n",
       "      <td>-0.125675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   q                               q_tokens  \\\n",
       "0    Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "1    Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "2    Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "3    Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "4    Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "..                               ...                                    ...   \n",
       "995  Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "996  Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "997  Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "998  Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "999  Multiline REGEX using VB Script  [multiline, regex, using, vb, script]   \n",
       "\n",
       "     init_pos                                               cand  \\\n",
       "0           0             Regex pattern not working in VB Script   \n",
       "1         369     Word counts in Python using regular expression   \n",
       "2         498  Convert Perl Regular Expression into Java Regu...   \n",
       "3         778  How to replace curly quotation marks in a stri...   \n",
       "4         848  ELM/Haskell : use Regular expression(Regex) to...   \n",
       "..        ...                                                ...   \n",
       "995       609             Symfony: Logs are not shown in Toolbar   \n",
       "996       580  NoClassDefFoundError during Tomcat graceful sh...   \n",
       "997       918  VectorKit crash reports with MKMapSnapshotter ...   \n",
       "998       629   NSURLConnection crash on releasing NSMutableData   \n",
       "999       790    HTTPS exception in 3G with some Android devices   \n",
       "\n",
       "                                           cand_tokens   cos_sim  \n",
       "0                [regex, pattern, working, vb, script]  0.830987  \n",
       "1    [word, counts, python, using, regular, express...  0.625896  \n",
       "2    [convert, perl, regular, expression, java, reg...  0.623632  \n",
       "3    [replace, curly, quotation, marks, string, usi...  0.614143  \n",
       "4    [elm, haskell, use, regular, expression, regex...  0.598888  \n",
       "..                                                 ...       ...  \n",
       "995                    [symfony, logs, shown, toolbar] -0.060448  \n",
       "996  [noclassdeffounderror, tomcat, graceful, shutd... -0.070299  \n",
       "997  [vectorkit, crash, reports, mkmapsnapshotter, ... -0.080530  \n",
       "998  [nsurlconnection, crash, releasing, nsmutabled... -0.113431  \n",
       "999           [https, exception, 3g, android, devices] -0.125675  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dfs[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL6_Rjg3InL8"
   },
   "source": [
    "### Эмбеддинги, обученные на корпусе похожих вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "iNvbpR5gJIPz"
   },
   "outputs": [],
   "source": [
    "train_data = read_corpus('./data/train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['converting string to list',\n",
       " 'Convert Google results object (pure js) to Python object']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr281ZyEJfjT"
   },
   "source": [
    "Улучшите качество модели.<br>Склеим вопросы в пары и обучим на них модель Word2Vec из gensim. Выберите размер window. Объясните свой выбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "f6Y46SSQMTL0"
   },
   "outputs": [],
   "source": [
    "'''your code'''\n",
    "\n",
    "train_data_list = []\n",
    "for pair in train_data:\n",
    "    pair_splitted = ' '.join(pair).split(' ')\n",
    "    train_data_list.append(pair_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['converting', 'string', 'to', 'list', 'Convert', 'Google', 'results', 'object', '(pure', 'js)', 'to', 'Python', 'object']\n"
     ]
    }
   ],
   "source": [
    "print(train_data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "QuJzAM0cI-UH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 21s, sys: 1.23 s, total: 5min 23s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "embeddings_trained = Word2Vec(train_data_list, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=5).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "OQonbm4nMenD"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397d68af6a4047bcbf6b0bad9741e225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 91.2 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking_trained = []\n",
    "test_dfs_trained = []\n",
    "# max_validation_examples = 1000\n",
    "max_validation_examples = 100\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks_tests = rank_candidates(q, ex, embeddings_trained, MyTokenizer_obj, test_out=True)\n",
    "    ranks = ranks_tests[0]\n",
    "    test_dfs_trained.append(ranks_tests[1])\n",
    "    # ranks = rank_candidates(q, ex, embeddings_trained, MyTokenizer_obj)\n",
    "    wv_ranking_trained.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "3kahBUPGMgGR"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284c01780f6240cfa2f5b71104732f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.320 | Hits@   1: 0.320\n",
      "DCG@   5: 0.409 | Hits@   5: 0.490\n",
      "DCG@  10: 0.439 | Hits@  10: 0.580\n",
      "DCG@ 100: 0.485 | Hits@ 100: 0.820\n"
     ]
    }
   ],
   "source": [
    "# for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "for k in tqdm([1, 5, 10, 100]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking_trained, k), k, hits_count(wv_ranking_trained, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 33s, sys: 1.34 s, total: 5min 34s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings_trained_3 = Word2Vec(train_data_list, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=3).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12974216e8de4a39b33a056d30f791c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 132 ms, total: 1min 13s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking_trained_3 = []\n",
    "test_dfs_trained_3 = []\n",
    "# max_validation_examples = 1000\n",
    "max_validation_examples = 100\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks_tests = rank_candidates(q, ex, embeddings_trained_3, MyTokenizer_obj, test_out=True)\n",
    "    ranks = ranks_tests[0]\n",
    "    test_dfs_trained_3.append(ranks_tests[1])\n",
    "    # ranks = rank_candidates(q, ex, embeddings_trained, MyTokenizer_obj)\n",
    "    wv_ranking_trained_3.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce876948a39c4e769c318b7d8cd68dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.320 | Hits@   1: 0.320\n",
      "DCG@   5: 0.410 | Hits@   5: 0.480\n",
      "DCG@  10: 0.430 | Hits@  10: 0.540\n",
      "DCG@ 100: 0.481 | Hits@ 100: 0.800\n"
     ]
    }
   ],
   "source": [
    "# for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "for k in tqdm([1, 5, 10, 100]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking_trained_3, k), k, hits_count(wv_ranking_trained_3, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 45s, sys: 1.19 s, total: 5min 46s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings_trained_10 = Word2Vec(train_data_list, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=10).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63a4a18cb14490bbc1fd2b94bb468f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 116 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking_trained_10 = []\n",
    "test_dfs_trained_10 = []\n",
    "# max_validation_examples = 1000\n",
    "max_validation_examples = 100\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks_tests = rank_candidates(q, ex, embeddings_trained_10, MyTokenizer_obj, test_out=True)\n",
    "    ranks = ranks_tests[0]\n",
    "    test_dfs_trained_10.append(ranks_tests[1])\n",
    "    # ranks = rank_candidates(q, ex, embeddings_trained, MyTokenizer_obj)\n",
    "    wv_ranking_trained_10.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13021aac5cff4609bf4c681c54ce70d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.320 | Hits@   1: 0.320\n",
      "DCG@   5: 0.404 | Hits@   5: 0.480\n",
      "DCG@  10: 0.438 | Hits@  10: 0.580\n",
      "DCG@ 100: 0.490 | Hits@ 100: 0.850\n"
     ]
    }
   ],
   "source": [
    "# for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "for k in tqdm([1, 5, 10, 100]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking_trained_10, k), k, hits_count(wv_ranking_trained_10, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------ Различные токенайзеры ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self, ext_tokenizer, ext_stopwords, ext_punctuation):\n",
    "        self.tokenizer = ext_tokenizer\n",
    "        self.stopwords = ext_stopwords\n",
    "        self.punctuation = ext_punctuation\n",
    "    def tokenize(self, text):\n",
    "        tokens = self.tokenizer.tokenize(text.lower())\n",
    "        tokens_no_sw_punct = [token for token in tokens if token not in self.stopwords and token not in self.punctuation]\n",
    "        return tokens_no_sw_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------- стемминг --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer_stem:\n",
    "    def __init__(self, ext_tokenizer, ext_stopwords, ext_punctuation, ext_stemmer):\n",
    "        self.tokenizer = ext_tokenizer\n",
    "        self.stopwords = ext_stopwords\n",
    "        self.punctuation = ext_punctuation\n",
    "        self.stemmer = ext_stemmer\n",
    "    def tokenize(self, text):\n",
    "        tokens = self.tokenizer.tokenize(text.lower())\n",
    "        tokens_no_sw_punct = [token for token in tokens if token not in self.stopwords and token not in self.punctuation]\n",
    "        tokens_no_sw_punct_stemmed = list(map(self.stemmer.stem, tokens_no_sw_punct))\n",
    "        return tokens_no_sw_punct_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = PorterStemmer()\n",
    "st = SnowballStemmer(language='english')\n",
    "MyTokenizer_stem_obj = MyTokenizer_stem(tk, sw, punct, st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dd08be56fa47438dd9601da1a86db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 231 ms, total: 1min 33s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking_stem = []\n",
    "test_dfs_stem = []\n",
    "# max_validation_examples = 1000\n",
    "max_validation_examples = 100\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks_tests = rank_candidates(q, ex, wv_embeddings, MyTokenizer_stem_obj, test_out=True)\n",
    "    ranks = ranks_tests[0]\n",
    "    test_dfs_stem.append(ranks_tests[1])\n",
    "    # ranks = rank_candidates(q, ex, wv_embeddings, MyTokenizer_obj)\n",
    "    wv_ranking_stem.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8984df10c9fe4143b41f0cb697a1713c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.320 | Hits@   1: 0.320\n",
      "DCG@   5: 0.403 | Hits@   5: 0.480\n",
      "DCG@  10: 0.412 | Hits@  10: 0.510\n",
      "DCG@ 100: 0.473 | Hits@ 100: 0.810\n"
     ]
    }
   ],
   "source": [
    "# for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "for k in tqdm([1, 5, 10, 100]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking_stem, k), k, hits_count(wv_ranking_stem, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6978423e8f784d5db114e9e74e0a4320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 242 ms, total: 1min 30s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking_trained_stem = []\n",
    "test_dfs_trained_stem = []\n",
    "# max_validation_examples = 1000\n",
    "max_validation_examples = 100\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks_tests = rank_candidates(q, ex, embeddings_trained, MyTokenizer_stem_obj, test_out=True)\n",
    "    ranks = ranks_tests[0]\n",
    "    test_dfs_trained_stem.append(ranks_tests[1])\n",
    "    # ranks = rank_candidates(q, ex, wv_embeddings, MyTokenizer_obj)\n",
    "    wv_ranking_trained_stem.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97605db44a684827835a0fc29c4db31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.240 | Hits@   1: 0.240\n",
      "DCG@   5: 0.318 | Hits@   5: 0.380\n",
      "DCG@  10: 0.341 | Hits@  10: 0.450\n",
      "DCG@ 100: 0.397 | Hits@ 100: 0.730\n"
     ]
    }
   ],
   "source": [
    "# for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "for k in tqdm([1, 5, 10, 100]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking_trained_stem, k), k, hits_count(wv_ranking_trained_stem, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------- лематизация --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/opv002/py_notes/stepik/Deep_Learning_MIPT_2/part_3/data/token_lemma_dict.json', 'r') as fp:\n",
    "    token_lemma_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18304\n"
     ]
    }
   ],
   "source": [
    "print(len(token_lemma_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer_lem:\n",
    "    def __init__(self, ext_tokenizer, ext_stopwords, ext_punctuation, ext_lemmas_dict):\n",
    "        self.tokenizer = ext_tokenizer\n",
    "        self.stopwords = ext_stopwords\n",
    "        self.punctuation = ext_punctuation\n",
    "        self.lemmer = ext_lemmas_dict\n",
    "    def tokenize(self, text):\n",
    "        tokens = self.tokenizer.tokenize(text.lower())\n",
    "        tokens_no_sw_punct = [token for token in tokens if token not in self.stopwords and token not in self.punctuation]\n",
    "        # tokens_no_sw_punct_lemmed = [self.lemmer[token] for token in tokens_no_sw_punct if token in tokens_no_sw_punct]\n",
    "        tokens_no_sw_punct_lemmed = []\n",
    "        for token in tokens_no_sw_punct:\n",
    "            if token in self.lemmer:\n",
    "                tokens_no_sw_punct_lemmed.append(self.lemmer[token])\n",
    "        return tokens_no_sw_punct_lemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyTokenizer_lem_obj = MyTokenizer_lem(tk, sw, punct, token_lemma_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4d0129507646b9880398301feb37ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 155 ms, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking_lem = []\n",
    "test_dfs_lem = []\n",
    "# max_validation_examples = 1000\n",
    "max_validation_examples = 100\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks_tests = rank_candidates(q, ex, wv_embeddings, MyTokenizer_lem_obj, test_out=True)\n",
    "    ranks = ranks_tests[0]\n",
    "    test_dfs_lem.append(ranks_tests[1])\n",
    "    # ranks = rank_candidates(q, ex, wv_embeddings, MyTokenizer_obj)\n",
    "    wv_ranking_lem.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274a5f3e3bd04a5f89b33d5472e85e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.420 | Hits@   1: 0.420\n",
      "DCG@   5: 0.500 | Hits@   5: 0.570\n",
      "DCG@  10: 0.537 | Hits@  10: 0.680\n",
      "DCG@ 100: 0.585 | Hits@ 100: 0.920\n"
     ]
    }
   ],
   "source": [
    "# for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "for k in tqdm([1, 5, 10, 100]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking_lem, k), k, hits_count(wv_ranking_lem, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee746bc0499749c99cc35bd68818a87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 128 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking_trained_lem = []\n",
    "test_dfs_trained_lem = []\n",
    "# max_validation_examples = 1000\n",
    "max_validation_examples = 100\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks_tests = rank_candidates(q, ex, embeddings_trained, MyTokenizer_lem_obj, test_out=True)\n",
    "    ranks = ranks_tests[0]\n",
    "    test_dfs_trained_lem.append(ranks_tests[1])\n",
    "    # ranks = rank_candidates(q, ex, wv_embeddings, MyTokenizer_obj)\n",
    "    wv_ranking_trained_lem.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222518015d9f413dab22fd3788eb2654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.270 | Hits@   1: 0.270\n",
      "DCG@   5: 0.368 | Hits@   5: 0.450\n",
      "DCG@  10: 0.406 | Hits@  10: 0.570\n",
      "DCG@ 100: 0.446 | Hits@ 100: 0.760\n"
     ]
    }
   ],
   "source": [
    "# for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "for k in tqdm([1, 5, 10, 100]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking_trained_lem, k), k, hits_count(wv_ranking_trained_lem, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY8PxB0j-ThG"
   },
   "source": [
    "### Замечание:\n",
    "Решить эту задачу с помощью обучения полноценной нейронной сети будет вам предложено, как часть задания в одной из домашних работ по теме \"Диалоговые системы\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vymVj8IxO2PO"
   },
   "source": [
    "Напишите свой вывод о полученных результатах.\n",
    "* Какой принцип токенизации даёт качество лучше и почему?\n",
    "* Помогает ли нормализация слов?\n",
    "* Какие эмбеддинги лучше справляются с задачей и почему?\n",
    "* Почему получилось плохое качество решения задачи?\n",
    "* Предложите свой подход к решению задачи.\n",
    "\n",
    "## Вывод:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emODHztAQUQz"
   },
   "source": [
    " - Какой принцип токенизации даёт качество лучше и почему?\n",
    "\n",
    "WordPunctTokenizer дает лучшее качество, так как позволяет очистить текст от пунктуации\n",
    "\n",
    " - Помогает ли нормализация слов?\n",
    "\n",
    "Да, лемматизация слов улучшает качество ранжирования (стоит отметить, что стемизация его ухудшает).\n",
    "\n",
    " - Какие эмбеддинги лучше справляются с задачей и почему?\n",
    "\n",
    "Предобученные эмбединги справляются лучше. Возможно, потому что при их обучении испольовался много больший объем данных и они лучше улавливают смысловую связь между словами за счет этого.\n",
    "\n",
    " - Почему получилось плохое качество решения задачи?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BIWqBuEa6j0b",
    "uS9FwWNd5a3S",
    "MQk_rolFwT_h",
    "ai48-5vv6j1d",
    "Y60z4t6W6j16",
    "0sUSxk866j1_",
    "J5xWOORI6j2F",
    "tHZqgDTo6j0i",
    "ySQQp0oQt1Ep",
    "LL6_Rjg3InL8"
   ],
   "name": "[homework]simple_embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
